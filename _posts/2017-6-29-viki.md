---
layout: post
title: Scripting on a Smartphone
headline: I was overseas with minimal wifi connection, and no access to a laptop or PC, 
          on a family backpacking trip. Here's an account of my experiences coding in the 
          Italian countryside with pen, paper, and a bash emulator Android app.
---

Around a month ago, a company (which I won't name) contacted me with the next steps of their internship application processes. 
I never expected to hear back from this company this late into the intern application season, but here it was. An email detailing a take-home assignment
I was supposed to finish within the next couple days. Except I wasn't home. I was overseas with minimal wifi connection, and no access to a laptop or PC, 
on a family backpacking trip that we had been planning for the entire year. Here's an account of my experiences coding in the 
Italian countryside with pen, paper, and a bash emulator Android app.

The day I received the spec I had internet connection, so I quickly did some research, downloading any and all web pages that 
were relevant. The task was to query an online video streaming service, and count the number of HD and non-HD videos there were
total. 

I wrote the script in Python because I already had it installed on a bash emulator app I had installed on my Android phone.
The first step was to define a function that built queries for me.

{% highlight python %}
# makes the query string, including required SHA1-HMAC
def make_query():
    unix_time = str(int(time.time()))
    msg = ENDPOINT + '?app=' + APP + '&per_page=' + per_page + '&page=' + str(page_num) + '&t=' + unix_time
    h = hmac.new(bytes(SECRET, 'UTF-8'), bytes(msg, 'UTF-8'), sha1)
    return msg + '&sig=' + h.hexdigest()
{% endhighlight %}

Each call is required to have a timestamp, which I calculate and assign to the variable 'unix_time'. I then construct part 
of the query as the string 'msg'. The reason I do that is because API spec requires the construction of a SHA-1 HMAC, with the query 
and an app secret 'SECRET' that corresponds to a registered app code, which I called 'APP'. (Note: I encoded the strings 'SECRET'
and 'msg' because I was working in Python 3.) I then concatenated the HMAC onto the query and return everything as a string. 

Another useful function I defined was the following, which simply makes a GET request with the Python Requests library: 

{% highlight python %}
# makes a GET request 
def make_request():
    query = make_query()
    r = requests.get(URL + query, headers =HEADERS )
    return r.json()
{% endhighlight %}

Here I call the previously defined 'make_query' method to define a string 'query' I use to build the final URL I call
with Python Requests. For the headers, I pass in user agent data to keep the API from blocking my connection. 

One catch I noticed in the spec was that I could only search the website page by page, 10 videos at a time. 
I knew some sites block your connection after requesting data too quickly, so included a try/catch to GET or system sleep.

{% highlight python %}
def count_hd():
    #keep requesting data while there are more pages to load 
    global page_num, hd, nonhd, more

    while more:
        try:
            obj = make_request()
        except:
            # if blocked, stop for a while 
            sleep(5)
            continue

        #parse the JSON response 
        more = obj['more']
        arr = obj['response']

        #count the HD and non HD videos 
        for el in arr:
            if el['flags']['hd']:
                hd+=1
            else:
                nonhd+=1

        page_num += 1

    #print the results 
    print('hd: ', hd)
    print('nonhd: ', nonhd)

{% endhighlight %}

I left some of the more boring parts of the assignment out, like declaring variables, JSON response structure, etc, but 
rest assured that the script worked after I tested it in a free city wifi area (these were amazing). All in all, the entire experience
was hectic and rushed, but I finished the assignment in the end. After sending my solution over via GitHub repo link (doing this
via mobile was a challenge itself) I was glad to hear days later that I had been chosen to advance to the next steps of 
recruitment. 